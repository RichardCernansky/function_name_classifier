{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2c909b3c341b53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:53:52.993966Z",
     "start_time": "2024-10-04T10:53:52.990527Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import ndjson\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Activation, Lambda, Concatenate, Softmax, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import pad_sequences,plot_model\n",
    "from tensorflow.keras.activations import softmax\n",
    "\n",
    "from collections import OrderedDict #for ordered sets of the data\n",
    "\n",
    "functionsASTs_file = 'functionsASTs.ndjson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e8309b-79b6-423a-8d90-7cbb4e784b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    def __init__(self, b_i: Optional[int], kind: str, code_pos: str, data: str):\n",
    "        self.branching_idx = b_i\n",
    "        self.parent = None\n",
    "        self.children = []\n",
    "        self.kind = kind\n",
    "        self.code_pos = code_pos\n",
    "        self.data = data\n",
    "\n",
    "    def set_parent(self, parent: 'Node'):\n",
    "        self.parent = parent\n",
    "\n",
    "    def add_child(self, child: 'Node'):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Convert the node and its children to a dictionary.\"\"\"\n",
    "        return {\n",
    "            'kind': self.kind,\n",
    "            'code_pos': self.code_pos,\n",
    "            'data': self.data,\n",
    "            'children': [child.to_dict() for child in self.children]\n",
    "        }\n",
    "\n",
    "def json_to_tree(data: dict) -> Node:\n",
    "    \"\"\"\n",
    "    Recursively builds a tree of Node objects from a JSON dictionary.\n",
    "    \"\"\"\n",
    "    node = Node(\n",
    "        b_i=None,\n",
    "        kind=data.get('kind'),\n",
    "        code_pos=data.get('code_pos'),\n",
    "        data=data.get('data')\n",
    "    )\n",
    "\n",
    "    # Recursively add children\n",
    "    for child_data in data.get('children', []):\n",
    "        child_node = json_to_tree(child_data)\n",
    "        child_node.set_parent(node)  # Set the parent for the child node\n",
    "        node.add_child(child_node)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fa5b84-1041-41db-a23d-3647f362f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NODE TO NODE PATHS\n",
    "# Function to collect all leaf nodes iteratively using DFS\n",
    "def collect_leaves_iterative(root):\n",
    "    if root is None:\n",
    "        return []\n",
    "\n",
    "    stack = [(root, [])]  # Stack to store (node, path_from_root)\n",
    "    leaves = []  # List to store leaf nodes and their paths\n",
    "\n",
    "    while stack:\n",
    "        node, path = stack.pop()\n",
    "        current_path = path + [node.kind]  # Update the current path\n",
    "\n",
    "        # leaf node - has no children\n",
    "        if not node.children:\n",
    "            leaves.append((node, current_path))\n",
    "\n",
    "        # push the children to the stack for DFS\n",
    "        children = reversed(node.children)\n",
    "        for child in children:  # process children in order on the stack\n",
    "            stack.append((child, current_path))\n",
    "\n",
    "    return leaves\n",
    "\n",
    "\n",
    "# Function to find the Lowest Common Ancestor (LCA) iteratively\n",
    "def find_lca_iterative(n1_path, n2_path):\n",
    "    length = len(n1_path) if len(n1_path) < len(n2_path) else len(n2_path)\n",
    "\n",
    "    lca = None\n",
    "    for i in range(length):\n",
    "        if n1_path[i] == n2_path[i]:\n",
    "            lca = n1_path[i]\n",
    "        else:\n",
    "            break\n",
    "    return lca\n",
    "\n",
    "\n",
    "def find_leaf_to_leaf_paths_iterative(root):\n",
    "    leaf_nodes = collect_leaves_iterative(root)\n",
    "\n",
    "    #list of all leaf-to-leaf paths\n",
    "    leaf_to_leaf_paths = []\n",
    "\n",
    "    # Iterate over each pair of leaf nodes\n",
    "    for i in range(len(leaf_nodes)):\n",
    "        for j in range(i + 1, len(leaf_nodes)):\n",
    "            leaf1, path1 = leaf_nodes[i]\n",
    "            leaf2, path2 = leaf_nodes[j]\n",
    "\n",
    "            # find lca\n",
    "            lca = find_lca_iterative(path1, path2)\n",
    "\n",
    "            # find the indexes\n",
    "            lca_index1 = path1.index(lca)\n",
    "            lca_index2 = path2.index(lca)\n",
    "\n",
    "            # Path from leaf1 to leaf2 via the LCA\n",
    "            path_to_lca_from_leaf1 = path1[:lca_index1 + 1]\n",
    "            path_to_lca_from_leaf2 = path2[:lca_index2 + 1]\n",
    "            path_to_lca_from_leaf2.reverse()\n",
    "\n",
    "            #combine the paths\n",
    "            complete_path = path_to_lca_from_leaf1 + path_to_lca_from_leaf2[1:]\n",
    "\n",
    "            # Add the complete leaf-to-leaf path to the result\n",
    "            leaf_to_leaf_paths.append((leaf1.data,)+tuple(complete_path)+(leaf2.data,))\n",
    "            \n",
    "\n",
    "    return [node.data for node,path in leaf_nodes], leaf_to_leaf_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b22f4b-2e73-436f-8973-a39494496b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tag(root) -> str:\n",
    "    # root is FunctionDefinition\n",
    "    definition_node = root\n",
    "    for definition_child in definition_node.children:\n",
    "        if definition_child.kind == \"FunctionDeclarator\":\n",
    "            declarator_node = definition_child\n",
    "            for declarator_child in declarator_node.children:\n",
    "                if declarator_child.kind == \"IdentifierDeclarator\":\n",
    "                    return str(declarator_child.data)\n",
    "\n",
    "    \n",
    "def generate_vocabs(file_path):\n",
    "    # Open the .ndjson file\n",
    "    with open(file_path, 'r') as ndjson_file:\n",
    "        # Load the file content\n",
    "        data = ndjson.load(ndjson_file)\n",
    "\n",
    "        # Initialize empty sets\n",
    "        value_vocab = set()  # Set of all leaf values\n",
    "        path_vocab = set()   # Set of all distinct paths\n",
    "        tags_vocab = set()   # Set of all distinct function tags\n",
    "\n",
    "        # Add '<PAD>' token before constructing the dictionaries\n",
    "        value_vocab.add('<PAD>')\n",
    "        path_vocab.add(('<PAD>',)) #tuple format\n",
    "        tags_vocab.add('<PAD>')\n",
    "\n",
    "        # Ensure that '<PAD>' gets index 0, and the other tokens start from index 1\n",
    "        value_vocab_dict = {'<PAD>': 0}\n",
    "        path_vocab_dict = {('<PAD>',): 0}\n",
    "        tags_vocab_dict = {'<PAD>': 0}\n",
    "        \n",
    "        max_num_contexts = 0\n",
    "        \n",
    "        for function_json in data:\n",
    "            # Convert each line (function) to a tree\n",
    "            func_root = json_to_tree(function_json)\n",
    "            tag = find_tag(func_root)\n",
    "            func_values, func_paths = find_leaf_to_leaf_paths_iterative(func_root)\n",
    "            max_num_contexts = max(len(func_paths), max_num_contexts)\n",
    "            \n",
    "            # Update vocabularies\n",
    "            value_vocab.update(func_values)  # Add function's values to value_vocab set\n",
    "            \n",
    "            # Convert each list in func_paths to a tuple before updating the set\n",
    "            path_vocab.update(path[1:-1] for path in func_paths)  # Add function's paths to path_vocab set\n",
    "            \n",
    "            tags_vocab.add(tag)  # add function's tag to tags_vocab set\n",
    "\n",
    "        # create dictionaries from the sets by assigning each value an index\n",
    "        value_vocab_dict = {value: idx+1 for idx, value in enumerate(sorted(value_vocab))}\n",
    "        path_vocab_dict = {path: idx+1 for idx, path in enumerate(sorted(path_vocab))}\n",
    "        tags_vocab_dict = {tag: idx+1 for idx, tag in enumerate(sorted(tags_vocab))}\n",
    "\n",
    "        return value_vocab_dict, path_vocab_dict, tags_vocab_dict, max_num_contexts\n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1223b71-ee0b-49d1-a72a-adf5c9b7ecf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T11:24:50.995399Z",
     "start_time": "2024-10-04T11:24:50.985255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------DONE--------------------\n",
      "value_vocab_size: 23114\n",
      "path_vocab_size: 62666\n",
      "tags_vocab_size: 7317\n",
      "max_num_contexts: 803278\n"
     ]
    }
   ],
   "source": [
    "value_vocab, path_vocab, tags_vocab, max_num_contexts = generate_vocabs(functionsASTs_file)\n",
    "\n",
    "#vocab sizes and embedding dimensions\n",
    "value_vocab_size = len(value_vocab)\n",
    "path_vocab_size = len(path_vocab)\n",
    "tags_vocab_size = len(tags_vocab)\n",
    "embedding_dim = 128 \n",
    "y = embedding_dim #must be >= emb_dim\n",
    "\n",
    "print(\"--------------------DONE--------------------\")\n",
    "print(f\"value_vocab_size: {value_vocab_size}\")\n",
    "print(f\"path_vocab_size: {path_vocab_size}\")\n",
    "print(f\"tags_vocab_size: {tags_vocab_size}\")\n",
    "print(f\"max_num_contexts: {max_num_contexts}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c704d7a0-43d8-4ec1-9f53-dc3715def898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedContextLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(WeightedContextLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention_weights, transformed_contexts = inputs\n",
    "        # Compute the weighted context\n",
    "        weighted_context = tf.reduce_sum(attention_weights * transformed_contexts, axis=1)\n",
    "        return weighted_context\n",
    "\n",
    "\n",
    "\n",
    "class TagEmbeddingMatrixLayer(Layer):\n",
    "    def __init__(self, tags_vocab_size, embedding_dim, **kwargs):\n",
    "        super(TagEmbeddingMatrixLayer, self).__init__(**kwargs)\n",
    "        self.tags_vocab_size = tags_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tag_embedding = None  # Initialize here\n",
    "        self.tag_embedding = Embedding(input_dim=self.tags_vocab_size, \n",
    "                                       output_dim=self.embedding_dim, \n",
    "                                       name='tag_embedding', \n",
    "                                       mask_zero=True)\n",
    "        \n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # transpose the tag embeddings\n",
    "        tags_embedding_matrix = self.tag_embedding(tf.range(self.tag_embedding.input_dim))  # Shape: (tags_vocab_size, embedding_dim)\n",
    "        tags_embedding_matrix_t = tf.transpose(tags_embedding_matrix)  # Shape: (embedding_dim, tags_vocab_size)\n",
    "        \n",
    "        # num_repeats based on the shape of weighted_context\n",
    "        num_repeats = tf.math.ceil( (tf.shape(inputs)[1] / tf.shape(tags_embedding_matrix_t)[0]))\n",
    "        num_repeats = tf.cast(num_repeats, tf.int32)  # Ensure it's an integer\n",
    "\n",
    "        # # tile it\n",
    "        tags_embedding_matrix_t_tiled = tf.tile(tags_embedding_matrix_t, [num_repeats, 1])  # Shape: (num_repeats * embedding_dim, tags_vocab_size)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # # only the required portion         # Shape: (weighted_context.shape[1], tags_vocab_size\n",
    "        matrix_final  = tf.matmul( inputs, tags_embedding_matrix_t_tiled[:(tf.shape(inputs)[1])] )\n",
    "        \n",
    "        return matrix_final\n",
    "\n",
    "def softmaxAxis1(x):\n",
    "    return softmax(x,axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d044f0c2-d048-4006-8038-93f8a60a2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bak_env/lib/python3.9/site-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'weighted_context_layer_9' (of type WeightedContextLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ value1_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">803278</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ path_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">803278</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ value2_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">803278</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ value_embedding     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">803278</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,958,592</span> │ value1_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ value2_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ path_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">803278</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,021,248</span> │ path_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">803278</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ value_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              │            │ path_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ value_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">803278</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ concatenate_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">803278</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ weighted_context_l… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">WeightedContextLa…</span> │                   │            │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tag_embedding_matr… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7317</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">936,576</span> │ weighted_context… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TagEmbeddingMatri…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7317</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ tag_embedding_ma… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ value1_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m803278\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ path_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m803278\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ value2_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m803278\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ value_embedding     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m803278\u001b[0m,    │  \u001b[38;5;34m2,958,592\u001b[0m │ value1_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │ value2_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ path_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m803278\u001b[0m,    │  \u001b[38;5;34m8,021,248\u001b[0m │ path_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m803278\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ value_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m384\u001b[0m)              │            │ path_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ value_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m803278\u001b[0m,    │     \u001b[38;5;34m49,280\u001b[0m │ concatenate_18[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m803278\u001b[0m, \u001b[38;5;34m1\u001b[0m) │        \u001b[38;5;34m129\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ weighted_context_l… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mWeightedContextLa…\u001b[0m │                   │            │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tag_embedding_matr… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7317\u001b[0m)      │    \u001b[38;5;34m936,576\u001b[0m │ weighted_context… │\n",
       "│ (\u001b[38;5;33mTagEmbeddingMatri…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax_7 (\u001b[38;5;33mSoftmax\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7317\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ tag_embedding_ma… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,965,825</span> (45.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,965,825\u001b[0m (45.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,965,825</span> (45.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,965,825\u001b[0m (45.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# dummies \n",
    "# value_vocab_size = 10000  # Example vocab size for value vocab\n",
    "# path_vocab_size = 5000    # Example vocab size for path vocab\n",
    "# tags_vocab_size = 1000    # Example tag vocab size\n",
    "# embedding_dim = 128       # Embedding dimension\n",
    "# num_context = 20          # Number of contexts for a single function\n",
    "\n",
    "# inputs for value1, path, and value2 (with num_context inputs per batch)\n",
    "input_value1 = Input(shape=(max_num_contexts,), name='value1_input')\n",
    "input_path = Input(shape=(max_num_contexts,), name='path_input')\n",
    "input_value2 = Input(shape=(max_num_contexts,), name='value2_input')\n",
    "\n",
    "# embedding layers with mask_zero=True to handle padding (index 0)\n",
    "value_embedding = Embedding(input_dim=value_vocab_size, output_dim=embedding_dim, name='value_embedding', mask_zero=True)\n",
    "path_embedding = Embedding(input_dim=path_vocab_size, output_dim=embedding_dim, name='path_embedding', mask_zero=True)\n",
    "\n",
    "# embed the inputs\n",
    "embedded_value1 = value_embedding(input_value1)  # shape: (None, num_context, embedding_dim)\n",
    "embedded_path = path_embedding(input_path)      # shape: (None, num_context, embedding_dim)\n",
    "embedded_value2 = value_embedding(input_value2)  # shape: (None, num_context, embedding_dim)\n",
    "\n",
    "# concatenate along the last axis (for each context, value1, path, and value2 are concatenated)\n",
    "embedded_concat = Concatenate(axis=-1)([embedded_value1, embedded_path, embedded_value2])\n",
    "# Shape: (None, num_context, 3 * embedding_dim)\n",
    "\n",
    "# apply a dense transformation to each concatenated context (row-wise transformation)\n",
    "transformed_contexts = Dense(units=y, activation='tanh')(embedded_concat)\n",
    "# Shape: (None, num_context, y)\n",
    "\n",
    "# attention mechanism\n",
    "attention_weights = Dense(1, activation=softmaxAxis1)(transformed_contexts)\n",
    "# Shape: (None, num_context,1) - attention scores for each context\n",
    "\n",
    "# apply attention weights to get the weighted sum of contexts\n",
    "weighted_context = WeightedContextLayer()([attention_weights, transformed_contexts])\n",
    "# shape: (None, y) - weighted sum across contexts\n",
    "\n",
    "#get tags_embeddings transposed\n",
    "tag_scores = TagEmbeddingMatrixLayer(tags_vocab_size, embedding_dim)(weighted_context) \n",
    "\n",
    "\n",
    "output_tensor = Softmax()(tag_scores)\n",
    "\n",
    "# define the model\n",
    "model = Model(inputs=[input_value1, input_path, input_value2], outputs=output_tensor)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "121ce985-efce-4cd5-960e-99948d4081d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "sts_indices shape: (1, 803278)\n",
      "paths_indices shape: (1, 803278)\n",
      "ets_indices shape: (1, 803278)\n",
      "tag_index shape: (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 19:24:15.078802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotrenovano\n",
      "training done\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "\n",
    "print(\"hi\")\n",
    "\n",
    "with open(functionsASTs_file, 'r') as ndjson_file:\n",
    "    # Load the file content\n",
    "    data = ndjson.load(ndjson_file)\n",
    "\n",
    "    for function_json in data:\n",
    "        # Convert each line (function) to a tree\n",
    "        func_root = json_to_tree(function_json)\n",
    "        tag = find_tag(func_root)\n",
    "        _, func_paths = find_leaf_to_leaf_paths_iterative(func_root) #get all contexts\n",
    "\n",
    "        sts_indices = []     #start terminals indices\n",
    "        paths_indices = []   #path indices\n",
    "        ets_indices = []     #end terminals indices\n",
    "        \n",
    "        tag_index = tags_vocab[tag]  #get the tag value\n",
    "        \n",
    "        for path in func_paths: # map to the indices\n",
    "            sts_indices.append(value_vocab[path[0]])    #get the terminal node's data\n",
    "            paths_indices.append(path_vocab[path[1:-1]]) #get the path nodes' kinds\n",
    "            ets_indices.append(value_vocab[path[-1]])   #get the ending terminal node's data\n",
    "\n",
    "\n",
    "        # Use Keras `pad_sequences` for consistent padding to max_num_contexts\n",
    "        sts_indices = pad_sequences([sts_indices], maxlen=max_num_contexts, padding='post', value=0)\n",
    "        paths_indices = pad_sequences([paths_indices], maxlen=max_num_contexts, padding='post', value=0)\n",
    "        ets_indices = pad_sequences([ets_indices], maxlen=max_num_contexts, padding='post', value=0)\n",
    "        \n",
    "        \n",
    "        # Convert inputs to the right data type (int64) if needed\n",
    "        sts_indices = np.array(sts_indices, dtype=np.int64)\n",
    "        paths_indices = np.array(paths_indices, dtype=np.int64)\n",
    "        ets_indices = np.array(ets_indices, dtype=np.int64)\n",
    "        tag_index = np.array([tag_index], dtype=np.int64)  # Ensure tag_index has batch dimension\n",
    "\n",
    "        # Print the shapes for debugging\n",
    "        print(f\"sts_indices shape: {sts_indices.shape}\")\n",
    "        print(f\"paths_indices shape: {paths_indices.shape}\")\n",
    "        print(f\"ets_indices shape: {ets_indices.shape}\")\n",
    "        print(f\"tag_index shape: {tag_index.shape}\")\n",
    "        \n",
    "        model.train_on_batch(x=[sts_indices, paths_indices, ets_indices], y=tag_index)\n",
    "        print(\"dotrenovano\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(\"training done\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15202314-0cc5-4c47-942a-e8ffb21c4c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
