{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3d9c3-b751-454c-a890-0c96cf83b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import ndjson\n",
    "import pickle\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, b_i: Optional[int], kind: str, code_pos: str, data: str):\n",
    "        self.branching_idx = b_i\n",
    "        self.parent = None\n",
    "        self.children = []\n",
    "        self.kind = kind\n",
    "        self.code_pos = code_pos\n",
    "        self.data = data\n",
    "\n",
    "    def set_parent(self, parent: 'Node'):\n",
    "        self.parent = parent\n",
    "\n",
    "    def add_child(self, child: 'Node'):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Convert the node and its children to a dictionary.\"\"\"\n",
    "        return {\n",
    "            'kind': self.kind,\n",
    "            'code_pos': self.code_pos,\n",
    "            'data': self.data,\n",
    "            'children': [child.to_dict() for child in self.children]\n",
    "        }\n",
    "\n",
    "def json_to_tree(data: dict) -> Node:\n",
    "    \"\"\"\n",
    "    Recursively builds a tree of Node objects from a JSON dictionary.\n",
    "    \"\"\"\n",
    "    node = Node(\n",
    "        b_i=None,\n",
    "        kind=data.get('kind'),\n",
    "        code_pos=data.get('code_pos'),\n",
    "        data=data.get('data')\n",
    "    )\n",
    "\n",
    "\n",
    "    # Recursively add children\n",
    "    for child_data in data.get('children', []):\n",
    "        child_node = json_to_tree(child_data)\n",
    "        child_node.set_parent(node)  # Set the parent for the child node\n",
    "        node.add_child(child_node)\n",
    "\n",
    "    return node\n",
    "\n",
    "#NODE TO NODE PATHS\n",
    "# Function to collect all leaf nodes iteratively using DFS\n",
    "def collect_leaves_iterative(root):\n",
    "    if root is None:\n",
    "        return []\n",
    "\n",
    "\n",
    "    stack = [(root, [])]  # Stack to store (node, path_from_root)\n",
    "    leaves = []  # List to store leaf nodes and their paths\n",
    "\n",
    "    while stack:\n",
    "        node, path = stack.pop()\n",
    "        current_path = path + [node.kind]  # Update the current path\n",
    "\n",
    "        # leaf node - has no children\n",
    "        if not node.children:\n",
    "            leaves.append((node, current_path))\n",
    "\n",
    "        # push the children to the stack for DFS\n",
    "        children = reversed(node.children)\n",
    "        for child in children:  # process children in order on the stack\n",
    "            stack.append((child, current_path))\n",
    "\n",
    "    return leaves\n",
    "\n",
    "\n",
    "# Function to find the Lowest Common Ancestor (LCA) iteratively\n",
    "def find_lca_iterative(n1_path, n2_path):\n",
    "    length = len(n1_path) if len(n1_path) < len(n2_path) else len(n2_path)\n",
    "\n",
    "    lca = None\n",
    "    for i in range(length):\n",
    "        if n1_path[i] == n2_path[i]:\n",
    "            lca = n1_path[i]\n",
    "        else:\n",
    "            break\n",
    "    return lca\n",
    "\n",
    "\n",
    "def find_leaf_to_leaf_paths_iterative(root):\n",
    "    leaf_nodes = collect_leaves_iterative(root)\n",
    "\n",
    "    #list of all leaf-to-leaf paths\n",
    "    leaf_to_leaf_paths = []\n",
    "\n",
    "    # Iterate over each pair of leaf nodes\n",
    "    for i in range(len(leaf_nodes)):\n",
    "        for j in range(i + 1, len(leaf_nodes)):\n",
    "            leaf1, path1 = leaf_nodes[i]\n",
    "            leaf2, path2 = leaf_nodes[j]\n",
    "\n",
    "            # find lca\n",
    "            lca = find_lca_iterative(path1, path2)\n",
    "\n",
    "            # find the indexes\n",
    "            lca_index1 = path1.index(lca)\n",
    "            lca_index2 = path2.index(lca)\n",
    "\n",
    "            # Path from leaf1 to leaf2 via the LCA\n",
    "            path_to_lca_from_leaf1 = path1[:lca_index1 + 1]\n",
    "            path_to_lca_from_leaf2 = path2[:lca_index2 + 1]\n",
    "            path_to_lca_from_leaf2.reverse()\n",
    "\n",
    "            #combine the paths\n",
    "            complete_path = path_to_lca_from_leaf1 + path_to_lca_from_leaf2[1:]\n",
    "\n",
    "            # Add the complete leaf-to-leaf path to the result\n",
    "            leaf_to_leaf_paths.append((leaf1.data,)+tuple(complete_path)+(leaf2.data,))\n",
    "\n",
    "\n",
    "    return [node.data for node,path in leaf_nodes], leaf_to_leaf_paths\n",
    "\n",
    "def find_tag(root) -> str:\n",
    "    # root is FunctionDefinition\n",
    "    definition_node = root\n",
    "    for definition_child in definition_node.children:\n",
    "        if definition_child.kind == \"FunctionDeclarator\":\n",
    "            declarator_node = definition_child\n",
    "            for declarator_child in declarator_node.children:\n",
    "                if declarator_child.kind == \"IdentifierDeclarator\":\n",
    "                    return str(declarator_child.data)\n",
    "\n",
    "\n",
    "def generate_vocabs(file_paths):\n",
    "    # Open the .ndjson file\n",
    "        # Initialize empty sets\n",
    "    value_vocab = set()  # Set of all leaf values\n",
    "    path_vocab = set()   # Set of all distinct paths\n",
    "    tags_vocab = set()   # Set of all distinct function tags\n",
    "    max_num_contexts = 0\n",
    "    for path in file_paths:\n",
    "        with open(path, 'r') as ndjson_file:\n",
    "            # Load the file content\n",
    "            data = ndjson.load(ndjson_file)\n",
    "            \n",
    "            for function_json in data:\n",
    "                # Convert each line (function) to a tree\n",
    "                func_root = json_to_tree(function_json)\n",
    "                tag = find_tag(func_root)\n",
    "                func_values, func_paths = find_leaf_to_leaf_paths_iterative(func_root)\n",
    "                max_num_contexts = max(len(func_paths), max_num_contexts)\n",
    "                \n",
    "                # Update vocabularies\n",
    "                value_vocab.update(func_values)  # Add function's values to value_vocab set\n",
    "                \n",
    "                # Convert each list in func_paths to a tuple before updating the set\n",
    "                path_vocab.update(path[1:-1] for path in func_paths)  # Add function's paths to path_vocab set\n",
    "                \n",
    "                tags_vocab.add(tag)  # add function's tag to tags_vocab set\n",
    "    \n",
    "    # create dictionaries from the sets by assigning each value an index\n",
    "    value_vocab_dict = {value: idx+1 for idx, value in enumerate(sorted(value_vocab))}\n",
    "    path_vocab_dict = {path: idx+1 for idx, path in enumerate(sorted(path_vocab))}\n",
    "    tags_vocab_dict = {tag: idx+1 for idx, tag in enumerate(sorted(tags_vocab))}\n",
    "\n",
    "    # Append the padding values to the dictionaries\n",
    "    value_vocab_dict['<PAD>'] = 0\n",
    "    path_vocab_dict[('<PAD>',)] = 0\n",
    "    tags_vocab_dict['<PAD>'] = 0\n",
    "\n",
    "    #combine\n",
    "    vocabs_dict = {\n",
    "        'value_vocab': value_vocab_dict,\n",
    "        'path_vocab': path_vocab_dict,\n",
    "        'tags_vocab': tags_vocab_dict,\n",
    "        'max_num_contexts': max_num_contexts\n",
    "    }\n",
    "\n",
    "    return vocabs_dict\n",
    "\n",
    "vocabs_json = 'vocabs.pkl'\n",
    "train = 'strat_train_functionsASTs.ndjson'\n",
    "valid = 'strat_validate_functionsASTs.ndjson'\n",
    "\n",
    "print(\"Started generating vocabs...\")\n",
    "vocabs_dict = generate_vocabs([train, valid])\n",
    "with open(vocabs_json, 'wb') as f:\n",
    "    pickle.dump(vocabs_dict, f)\n",
    "\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
